{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d3ab388-9e4c-4c4e-93b3-2b5a7d294f7c",
      "metadata": {
        "id": "8d3ab388-9e4c-4c4e-93b3-2b5a7d294f7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18c2c8c-efdc-4d46-9562-3747fdb3f345"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import tqdm.notebook as tq\n",
        "import itertools\n",
        "import pickle\n",
        "from gensim.models import Word2Vec, Phrases\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d3ebc1-fdf6-45f2-9aa5-221e03f8c7f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0d3ebc1-fdf6-45f2-9aa5-221e03f8c7f8",
        "outputId": "4e828726-eb82-48d7-f01e-b363a5e142e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "POLITICS                0.194290\n",
            "SOCIAL                  0.105850\n",
            "RELIGION                0.102368\n",
            "LAW/ORDER               0.094708\n",
            "SOCIAL ISSUES           0.093315\n",
            "HEALTH                  0.088440\n",
            "ECONOMY                 0.059889\n",
            "FARMING                 0.054318\n",
            "SPORTS                  0.034123\n",
            "EDUCATION               0.029944\n",
            "RELATIONSHIPS           0.027159\n",
            "WILDLIFE/ENVIRONMENT    0.025070\n",
            "OPINION/ESSAY           0.018106\n",
            "LOCALCHIEFS             0.017409\n",
            "CULTURE                 0.016017\n",
            "WITCHCRAFT              0.011142\n",
            "MUSIC                   0.010446\n",
            "TRANSPORT               0.007660\n",
            "ARTS AND CRAFTS         0.004875\n",
            "FLOODING                0.004875\n",
            "Name: Label, dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv(\"Train.csv\")\n",
        "#train = train[train[\"Label\"].isin([\"POLITICS\", \"SOCIAL\", \"RELIGION\", \"LAW/ORDER\", \"SOCIAL ISSUES\", \"HEALTH\", \"ECONOMY\", \"FARMING\"])]\n",
        "#train[\"Label\"][train[\"Label\"].isin([\"FLOODING\", \"ARTS AND CRAFTS\", \"TRANSPORT\", \"MUSIC\", \"WITCHCRAFT\", \"CULTURE\", \"LOCALCHIEFS\", \"OPINION/ESSAY\"])] = \"OTHER\"\n",
        "train_data = train[\"Text\"]\n",
        "train_labels = train[\"Label\"]\n",
        "\n",
        "\n",
        "labels = train_labels.unique()\n",
        "print(train_labels.value_counts() / len(train_labels))\n",
        "\n",
        "int2Label = {}\n",
        "for i in range(len(labels)):\n",
        "    train_labels[train_labels == labels[i]] = i\n",
        "    int2Label[i] = labels[i]\n",
        "\n",
        "chichewa_tkns = []\n",
        "for s in train['Text']:\n",
        "  chichewa_tkns.append(word_tokenize(s))\n",
        "\n",
        "bigram_transformer = Phrases(chichewa_tkns)\n",
        "w2vmodel = Word2Vec(bigram_transformer[chichewa_tkns], size = 300, window = 5, min_count = 1, workers = 4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2vmodel.wv[\"Khansala\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9Em8xcCqXz0",
        "outputId": "b9f4cffc-b940-4547-ad92-e306bee582fd"
      },
      "id": "i9Em8xcCqXz0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.00470574e-04, -1.55389467e-02,  5.72375860e-03, -1.38007514e-02,\n",
              "       -1.71645507e-02,  1.12413634e-02, -2.10085455e-02, -5.08634932e-03,\n",
              "       -2.58624200e-02, -5.40621951e-03, -2.03608107e-02, -1.79518592e-02,\n",
              "       -2.21928358e-02, -2.32464895e-02, -1.38172582e-02, -2.14932952e-02,\n",
              "       -7.08893081e-03, -1.26597034e-02, -1.92087796e-02,  3.67085845e-03,\n",
              "       -2.91154925e-02,  1.17966356e-02, -5.96716022e-03,  6.73854537e-03,\n",
              "        1.04986122e-02,  1.62754580e-02, -2.52737254e-02,  7.81642087e-03,\n",
              "       -7.35861063e-02, -8.76481645e-03,  6.62795594e-03,  1.51552667e-03,\n",
              "       -2.08634939e-02,  2.74356101e-02, -1.81271452e-02, -1.13708777e-02,\n",
              "       -2.14615986e-02,  3.62631753e-02,  3.48301940e-02,  1.09075615e-02,\n",
              "        1.93806784e-03,  1.94540918e-02,  4.21503261e-02, -2.15377435e-02,\n",
              "       -5.78465359e-03,  7.10120751e-03,  5.58399130e-03,  2.74421778e-02,\n",
              "        3.11666843e-03, -3.47231477e-02, -2.50014532e-02, -8.29802174e-03,\n",
              "        6.40665274e-03,  8.73080920e-03, -8.66169017e-03,  9.95228416e-04,\n",
              "       -2.18070503e-02,  1.00165000e-02, -4.97167259e-02, -4.48080432e-03,\n",
              "       -3.03182080e-02,  1.41540496e-02,  1.35517018e-02,  2.41258480e-02,\n",
              "        3.92552465e-02,  9.39518027e-03, -3.64921018e-02, -2.91159702e-03,\n",
              "       -1.38036453e-03,  7.44016515e-03, -3.66740599e-02,  3.25939432e-02,\n",
              "        2.40135770e-02, -9.52565810e-04,  5.66760451e-03, -8.43151007e-03,\n",
              "        7.64407730e-03,  1.71807427e-02, -8.14616028e-03, -9.35904123e-03,\n",
              "       -7.12006353e-03,  1.40791142e-03, -1.72321666e-02,  1.88991614e-02,\n",
              "        3.23605873e-02,  5.31990314e-03, -1.20316668e-04,  5.98039627e-02,\n",
              "       -7.86120631e-03,  3.11084930e-02, -1.83526780e-02,  1.24796722e-02,\n",
              "       -3.21986936e-02, -9.09461582e-04,  5.15316520e-03,  1.24716088e-02,\n",
              "       -5.13275862e-02, -4.25731204e-03,  3.12863057e-03, -1.34063198e-03,\n",
              "        9.58579872e-03,  7.86095671e-03,  3.11953644e-03, -2.84778327e-02,\n",
              "        1.14721488e-05,  1.03739230e-02,  3.54471477e-03, -1.01512447e-02,\n",
              "        2.00764043e-03,  8.65332317e-03,  4.47070785e-02,  2.69297455e-02,\n",
              "        6.04840182e-03,  2.04055421e-02, -1.63504332e-02, -2.15260200e-02,\n",
              "        6.79807999e-05, -9.68121178e-03,  3.52801406e-04, -4.04861337e-03,\n",
              "        2.17368528e-02, -1.98084693e-02, -3.37584019e-02, -5.12829497e-02,\n",
              "        4.28963715e-04, -1.28850387e-02, -3.06075625e-02, -1.35374265e-02,\n",
              "       -2.31700763e-02, -1.82945039e-02, -2.28633396e-02,  3.34958523e-03,\n",
              "       -6.13849284e-03, -9.56924818e-03,  4.81557194e-03, -1.18726483e-02,\n",
              "       -3.17983358e-04,  1.11048566e-02, -1.67367402e-02, -1.94926839e-02,\n",
              "       -9.90925822e-03, -1.68362744e-02, -1.51304249e-02, -1.48515627e-02,\n",
              "       -1.59961097e-02, -1.00911893e-02, -3.56470980e-03, -1.93224140e-02,\n",
              "       -1.72666274e-02,  8.36006552e-03,  1.58613883e-02, -1.44397840e-02,\n",
              "       -3.70981693e-02, -2.29000207e-02, -2.84154788e-02, -3.10881226e-03,\n",
              "        1.70491785e-02,  6.18250901e-03, -2.21581757e-03, -4.07188833e-02,\n",
              "       -6.24229619e-03,  1.23248389e-03, -5.90809528e-03, -7.57097616e-04,\n",
              "       -1.32426352e-03,  1.97774600e-02,  1.12497555e-02, -4.76241577e-03,\n",
              "       -6.08186871e-02,  7.71375792e-03,  1.39670423e-03,  1.11187738e-03,\n",
              "        1.42051894e-02, -3.01896557e-02,  5.32401539e-03,  9.31821018e-03,\n",
              "       -5.08352481e-02,  1.34516582e-02, -2.02040356e-02,  2.11743265e-02,\n",
              "       -2.17629387e-03,  1.68067571e-02, -3.22065577e-02, -1.54123567e-02,\n",
              "        2.23303097e-03,  1.41807972e-02, -7.53128529e-03,  1.14708254e-02,\n",
              "       -6.07719179e-03, -5.16577624e-02,  4.23410581e-03, -1.62753370e-02,\n",
              "        5.50924465e-02, -3.41044292e-02, -1.42584313e-02, -1.41191836e-02,\n",
              "       -1.66963041e-02, -1.74213219e-02, -1.92900524e-02, -2.71092411e-02,\n",
              "       -1.66464411e-02,  1.74549496e-04, -7.49671785e-03,  1.29116029e-02,\n",
              "       -1.05105340e-02, -3.43371124e-04, -4.09244969e-02, -7.00229686e-03,\n",
              "       -4.24693478e-03, -4.20329757e-02,  8.36241804e-03, -2.68712677e-02,\n",
              "        1.85969789e-02, -3.58258151e-02,  8.16401467e-03,  1.95121719e-03,\n",
              "       -1.20392451e-02,  2.29810495e-02,  2.49632052e-03, -3.06148082e-03,\n",
              "        1.97171997e-02,  2.75306441e-02, -5.13940956e-03, -4.51007532e-03,\n",
              "        1.83415934e-02,  1.30454998e-03,  1.74101200e-02, -4.69031744e-02,\n",
              "       -2.79188864e-02, -1.04270587e-02, -1.10791838e-02, -4.44811843e-02,\n",
              "       -1.06217898e-02,  1.90329493e-03,  2.53994558e-02, -7.37489900e-03,\n",
              "        1.96726322e-02, -3.58236022e-02,  1.62604563e-02,  6.57133665e-03,\n",
              "        7.09688524e-03, -8.53906386e-03, -3.28588225e-02, -4.36949544e-02,\n",
              "       -1.71358846e-02,  3.04540619e-02, -1.20497597e-02, -2.72531677e-02,\n",
              "       -3.24252956e-02, -1.21799754e-02,  1.61523316e-02,  1.35779539e-02,\n",
              "       -8.65375903e-03, -3.32087884e-03, -4.03577834e-03, -8.32340389e-04,\n",
              "       -1.79816280e-02,  2.13725083e-02, -2.74011623e-02,  5.51012810e-03,\n",
              "        1.20901559e-02,  4.42460785e-03,  2.41267849e-02, -2.88742576e-02,\n",
              "        1.24584539e-02,  2.34333836e-02, -2.07317565e-02, -8.03017709e-03,\n",
              "       -1.24699064e-02, -5.22196591e-02,  7.31494976e-04, -1.32263601e-02,\n",
              "        4.55253497e-02,  1.76485777e-02, -1.62490644e-02, -3.07136141e-02,\n",
              "       -6.45341575e-02,  2.46563856e-03, -2.11004298e-02, -1.10321390e-02,\n",
              "       -4.51054005e-03,  1.29502807e-02,  1.57098118e-02, -8.67582578e-03,\n",
              "        2.17132512e-02, -1.24311829e-02,  5.79713620e-02, -7.18796765e-03,\n",
              "        1.85258593e-02,  2.06930432e-02, -5.81019558e-03, -1.95141807e-02,\n",
              "       -4.86421818e-03, -1.67236291e-02, -2.70073693e-02,  9.41478647e-03,\n",
              "        8.64923093e-03, -8.94580130e-03,  2.20722407e-02, -3.14232931e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With NN Embeddings"
      ],
      "metadata": {
        "id": "he6ifuKcqp3X"
      },
      "id": "he6ifuKcqp3X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1882aaf1-7339-407c-a56f-0543bc597df2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1882aaf1-7339-407c-a56f-0543bc597df2",
        "outputId": "9ba487d9-92cb-41d0-f878-af0fc996e1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47433\n",
            " Mwangonde: Khansala wachinyamata Akamati achinyamata ndi atsogoleri a mawa, ambiri amaganiza kuti izi ndi nkhambakamwa chabe. Koma achinyamata ena, monga Lusubilo Mwangonde, akukwaniritsa akupherezetsa mawuwa osati pongolota kuti adzakhala, koma kutsogolera kumene chifukwa nthawi yawo yakwana. DAILES BANDA adacheza ndi Mwangonde, khansala wachinyama, yemwe akuimira Jumbo Ward mumzinda wa Mzuzu, motere:  Chisale watuluka nkumangidwanso  Sipakala waimitsa Nyumba ya Malamulo  Pa Wenela pasintha zedi Ali ndi masomphenya: Mwangonde Tikudziweni  Ndine Lusubilo Mwangonde, ndili ndi zaka 27 zakubadwa. Ndinabadwa mbanja la ana asanu ndipo ndine wachinayi kubadwa. Ndimachokera mmudzi mwa Mwamalopa, kwa Paramount Chief Kyungu mboma la Karonga. Sindili pabanja pakadalipano.\n",
            " Mbiri ya maphunziro anu ndi yotani? Maphunziro anga a pulaimale ndidachitira kusukula yapulaiveti ya Viphya mumzinda wa Mzuzu ndipo asekondale ndidachitira pa Phwezi Boys mboma la Rumphi. Ndili ndi diploma ya Accounting ndipo pakadalipano ndikupanga digiri komanso Chartered Accounting kusukulu ya Malawi College of Accountancy (MCA).\n",
            " Mudayamba bwanji zandale? Kuyambira ndili wachichepere, zaka 12, ndakhala ndikukhala mumaudindo a utgogoleri. Ichi ndi china mwa zinthu zomwe zidandilimbikitsa kuti ndikhoza kudzapambana pazisankho. Koma chachikulu chomwe chidandichititsa kuti ndilowe ukhansala chidali chifukwa chakuti ndinkafuna kupereka mpata kwa anthu kuti azitha kuyankhula zakukhosi kwawo polimbikitsa demokalase ndi chitukuko.\n",
            " Ntchito mukugwira ndi zomwe munkayembekezera? Eya, ndiponso ndinkayembekezera zambiri.\n",
            " Masomphenya anu ndi otani pandale? Ine ndine munthu wokhulupirira Mulungu ndipo ndili ndi chikhulupiriro choti Iye ndi amene adzandionetsere zomwe ndikuyera kuchita ndi tsogolo langa.\n",
            " Zinthu zina zomwe mumachita ndi chiyani pambali pa ukhansala? Ndikakhala sindikugwira ntchito yaukhansala ndimakhala ndikuchita bizinesi, nthawi zina ndimakhala ndili kusukulu komwe ndikuchita maphuro anga a digiri. Kuonjezera pamenepo ndili ndi bungwe lomwe ndidayambitsa ndi anzanga ena la Centre for Participatory Democracy lomwe limalimbikitsa demokalase.\n",
            " Zomwe mwakwanitsa ndi zotani? Ndathandiza kuti ntchito yopala misewu ya kudera la Moyale itheke. Misewuyi yakhala nthawi yaitali osapalidwa. Ndidathandiziranso kuti ochita malonda ayambe kumanga mashopu anjerwa ndi kusiya kumangira matabwa kapena zigwagwa. Ndidakwanitsanso kukaimirira khonsolo ya Mzuzu ku Nyumba ya Malamulo. Ndaonanso kuti ntchitoyi yandithandiza kusintha momwe ndimaonera zinthu komanso ndimakumana ndi anthu osiyanasiyana omwe amandiphunzitsa zinthu zambiri.\n",
            "\n",
            "[92, 32, 187, 265, 3928, 92, 661, 32, 8, 155, 108, 3928, 1, 12149, 138, 41, 120, 92, 661, 92, 297, 836, 30, 312, 5, 917, 44, 1873, 9, 515, 7, 86, 9, 392, 25, 32, 3130, 49, 66, 1874, 40, 8, 1947, 19204, 138, 1, 19205, 334, 376, 25, 32, 1, 1948, 2, 8, 930, 3928, 12, 138, 1, 4311, 1014, 456, 26, 138, 59, 230, 3, 9, 19206]\n",
            "909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "train_sentences, test_sentences, y_train, y_test = train_test_split(train_data, train_labels, test_size = .1, stratify = train_labels)\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "x_train = tokenizer.texts_to_sequences(train_sentences)\n",
        "x_test = tokenizer.texts_to_sequences(test_sentences)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(vocab_size)\n",
        "print(train_sentences[0])\n",
        "print(x_train[0])\n",
        "maxLen = max([len(x_train[i]) for i in range(len(x_train))])\n",
        "print(maxLen)\n",
        "x_train = pad_sequences(x_train, padding = 'post', maxlen=maxLen)\n",
        "x_test = pad_sequences(x_test, padding = 'post', maxlen=maxLen)\n",
        "x_train = np.array(x_train, dtype=np.float)\n",
        "x_test = np.array(x_test, dtype=np.float)\n",
        "y_train = np.array(y_train, dtype=np.float)\n",
        "y_test = np.array(y_test, dtype=np.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cd274df-ca75-41a2-8841-caa691c1571b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cd274df-ca75-41a2-8841-caa691c1571b",
        "outputId": "93e25c3c-affb-4102-8b21-1722338bd1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 909, 100)          4743300   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 905, 128)          64128     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 20)                2580      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 20)                420       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,810,428\n",
            "Trainable params: 4,810,428\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Embedding(input_dim = vocab_size, output_dim = embedding_dim, input_length = maxLen))\n",
        "model.add(keras.layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(keras.layers.GlobalMaxPool1D())\n",
        "model.add(keras.layers.Dense(20, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(20, activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11822901-ab27-4a0a-a79d-7ad4527b8b3d",
      "metadata": {
        "id": "11822901-ab27-4a0a-a79d-7ad4527b8b3d"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs = 30, validation_data = (x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4987fe48-6111-4a9b-99c2-eb34591c63fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4987fe48-6111-4a9b-99c2-eb34591c63fc",
        "outputId": "a4dd503d-8660-4f7f-d934-96fa88db4ad7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5277777910232544"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test, verbose=False)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With TfIdf encodings, 64%"
      ],
      "metadata": {
        "id": "UM-i5Jc1qs4O"
      },
      "id": "UM-i5Jc1qs4O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad10a84d-a0f2-46d4-94d5-9010155ff521",
      "metadata": {
        "id": "ad10a84d-a0f2-46d4-94d5-9010155ff521",
        "outputId": "60bb185b-04b6-4b94-c4c3-c4bf265fca71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1292, 47229)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "x_train_vec = vectorizer.fit_transform(train_sentences)\n",
        "x_test_vec = vectorizer.transform(test_sentences)\n",
        "x_train_vec.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ac51f9-d13a-4e83-a966-aa0d27eedd37",
      "metadata": {
        "id": "e0ac51f9-d13a-4e83-a966-aa0d27eedd37"
      },
      "outputs": [],
      "source": [
        "def createVecModel(input_size, denseLayer, activation, dropout):\n",
        "    vecModel = keras.models.Sequential()\n",
        "    vecModel.add(keras.layers.InputLayer(input_size))\n",
        "    vecModel.add(keras.layers.Dense(denseLayer, activation=activation))\n",
        "    vecModel.add(keras.layers.Dropout(dropout))\n",
        "    vecModel.add(keras.layers.Dense(20, activation='softmax'))\n",
        "    vecModel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return vecModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2827dfa-6c8e-430e-8706-20efbc4fd366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2827dfa-6c8e-430e-8706-20efbc4fd366",
        "outputId": "f9cafff5-f80f-4077-c23f-ca347bd4ff38"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "params = [[100, 200, 300, 400, 500],\n",
        "          ['elu', 'relu', 'selu', 'tanh'],\n",
        "          [.4, .6, .8, .9]\n",
        "         ]\n",
        "params = itertools.product(*params)\n",
        "params = list(params)\n",
        "len(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229962d9-71f1-445d-93d8-b703720bb03c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "4677b729c6ab4237ab4345d8d3c9ada7",
            "6a139dc14b3445ebabc6d9a9f1daf720",
            "e2b6911299d949f38891c4b7afdad721",
            "f826ad9260534c0293145487b1c69d1e",
            "71cd52facb504d3db4909c36390e802a",
            "1f1fa18498e8435c9ddae3a2ad2b15f1",
            "eeb83734567740daa46a3e763c2b6696",
            "27928ed925164dea80c525ae802ee491",
            "97f4a0a2a0514caca90387c176b074a8",
            "1507cfae10274087a967724271e312eb",
            "f2e6b37f070f4b4dbf5569d8e047924e"
          ]
        },
        "id": "229962d9-71f1-445d-93d8-b703720bb03c",
        "outputId": "24ce29ff-8d7c-4631-93eb-f4331539ba94"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/80 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4677b729c6ab4237ab4345d8d3c9ada7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params:  (100, 'elu', 0.4)\n",
            "Best Accuracy:  0.6288300901651382\n",
            "Best Params:  (100, 'elu', 0.6)\n",
            "Best Accuracy:  0.6302228569984436\n",
            "Best Params:  (100, 'selu', 0.4)\n",
            "Best Accuracy:  0.6323119699954987\n",
            "Best Params:  (100, 'selu', 0.8)\n",
            "Best Accuracy:  0.6350974887609482\n",
            "Best Params:  (100, 'tanh', 0.4)\n",
            "Best Accuracy:  0.6357938796281815\n",
            "Best Params:  (200, 'elu', 0.6)\n",
            "Best Accuracy:  0.6364902406930923\n",
            "Best Params:  (200, 'relu', 0.4)\n",
            "Best Accuracy:  0.6371866166591644\n",
            "Best Params:  (200, 'selu', 0.4)\n",
            "Best Accuracy:  0.638579398393631\n",
            "Best Params:  (200, 'tanh', 0.4)\n",
            "Best Accuracy:  0.6399721503257751\n",
            "Best Params:  (300, 'elu', 0.6)\n",
            "Best Accuracy:  0.6406685262918472\n",
            "Best Params:  (300, 'selu', 0.8)\n",
            "Best Accuracy:  0.6476323157548904\n",
            "(300, 'selu', 0.8) 0.6476323157548904\n"
          ]
        }
      ],
      "source": [
        "skf = StratifiedKFold(n_splits=4)\n",
        "vectorizer = TfidfVectorizer()\n",
        "best_acc = 0\n",
        "best_params = None\n",
        "for combo in tq.tqdm(params):\n",
        "    denseLayer, activation, dropout = combo\n",
        "    acc = 0\n",
        "    for trainidx, testidx in skf.split(train_data, LabelEncoder().fit_transform(train_labels)):\n",
        "        x_train, y_train = train_data[trainidx], train_labels[trainidx]\n",
        "        x_test, y_test = train_data[testidx], train_labels[testidx]\n",
        "        \n",
        "        x_train_vec = vectorizer.fit_transform(x_train)\n",
        "        x_test_vec = vectorizer.transform(x_test)\n",
        "        \n",
        "        x_train_vec = x_train_vec.toarray()\n",
        "        x_test_vec = x_test_vec.toarray()\n",
        "        y_train = np.array(y_train, dtype='float')\n",
        "        y_test = np.array(y_test, dtype='float')\n",
        "        \n",
        "        vecModel = createVecModel(x_train_vec.shape[1], denseLayer, activation, dropout)\n",
        "        vecModel.fit(x_train_vec, y_train, epochs = 12, verbose = False)\n",
        "        acc += vecModel.evaluate(x_test_vec, y_test, verbose = False)[1]\n",
        "\n",
        "        del vecModel\n",
        "    acc /= 4\n",
        "    \n",
        "    if acc > best_acc:\n",
        "        best_acc = acc\n",
        "        best_params = (denseLayer, activation, dropout)\n",
        "        print(\"Best Params: \", best_params)\n",
        "        print(\"Best Accuracy: \", best_acc)\n",
        "    \n",
        "\n",
        "\n",
        "print(best_params, best_acc)\n",
        "with open(\"best_params_acc.txt\", \"wb\") as file:\n",
        "    pickle.dump((best_params, best_acc), file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = train_data\n",
        "y_train = train_labels\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "x_train_vec = vectorizer.fit_transform(x_train)\n",
        "x_train_vec = x_train_vec.toarray()\n",
        "y_train = np.array(y_train, dtype='float')\n",
        "\n",
        "model = createVecModel(x_train_vec.shape[1], 600, 'selu', .9)\n",
        "model.fit(x_train_vec, y_train, epochs=12)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfetm-8Udvhg",
        "outputId": "d954324f-d66d-41fb-ec55-a52f4d844728"
      },
      "id": "qfetm-8Udvhg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 2.6128 - accuracy: 0.1971\n",
            "Epoch 2/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.9076 - accuracy: 0.4269\n",
            "Epoch 3/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 1.4067 - accuracy: 0.6734\n",
            "Epoch 4/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.9841 - accuracy: 0.7994\n",
            "Epoch 5/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.6934 - accuracy: 0.8712\n",
            "Epoch 6/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.4652 - accuracy: 0.9297\n",
            "Epoch 7/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.3353 - accuracy: 0.9547\n",
            "Epoch 8/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.2277 - accuracy: 0.9735\n",
            "Epoch 9/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.1601 - accuracy: 0.9868\n",
            "Epoch 10/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.1126 - accuracy: 0.9903\n",
            "Epoch 11/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0857 - accuracy: 0.9937\n",
            "Epoch 12/12\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0637 - accuracy: 0.9965\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2b4516bfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(\"Test.csv\")\n",
        "x_test = test[\"Text\"]\n",
        "x_test_vec = vectorizer.transform(x_test)\n",
        "x_test_vec = x_test_vec.toarray()\n",
        "preds = np.argmax(model.predict(x_test_vec), axis=1)\n",
        "preds = [int2Label[pred] for pred in preds]\n",
        "for i in range(len(preds)):\n",
        "  if preds[i] == 'OTHER':\n",
        "    preds[i] = np.random.choice([\"FLOODING\", \"ARTS AND CRAFTS\", \"TRANSPORT\", \"MUSIC\", \"WITCHCRAFT\", \"CULTURE\", \"LOCALCHIEFS\", \"OPINION/ESSAY\"])\n",
        "test[\"Label\"] = preds\n",
        "test[[\"ID\", \"Label\"]].to_csv(\"submission_nn.csv\", index=False)"
      ],
      "metadata": {
        "id": "w1uRY5KvecXC"
      },
      "id": "w1uRY5KvecXC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With word2vec"
      ],
      "metadata": {
        "id": "uXCgXIQDqmfO"
      },
      "id": "uXCgXIQDqmfO"
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_w2v(s):\n",
        "  vec = 0\n",
        "  n = 0\n",
        "  for token in word_tokenize(s):\n",
        "    try:\n",
        "      vec += w2vmodel.wv[token]\n",
        "      n += 1\n",
        "    except:\n",
        "      pass\n",
        "  return vec / n"
      ],
      "metadata": {
        "id": "tvorl1vAqzJ_"
      },
      "id": "tvorl1vAqzJ_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(train_data, train_labels, test_size = .2, stratify = train_labels)\n",
        "\n",
        "x_train_w2v = np.array([vectorize_w2v(x) for x in x_train.values])\n",
        "x_test_w2v = np.array([vectorize_w2v(x) for x in x_test.values])\n",
        "y_train = np.array(y_train, dtype='float')\n",
        "y_test = np.array(y_test, dtype='float')"
      ],
      "metadata": {
        "id": "laDMInWTru4w"
      },
      "id": "laDMInWTru4w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_w2v.shape, x_test_w2v.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1JyCwRKsHoc",
        "outputId": "cb59b6f3-adb5-4267-d617-48bf348e05b2"
      },
      "id": "J1JyCwRKsHoc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1148, 300), (288, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.InputLayer(x_train_w2v.shape[1]))\n",
        "model.add(keras.layers.Dense(1000, activation='relu'))\n",
        "model.add(keras.layers.Dense(1000, activation='relu'))\n",
        "model.add(keras.layers.Dense(20, activation='softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.fit(x_train_w2v, y_train, epochs = 100, validation_data=(x_test_w2v, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1V9De3Xjsgle",
        "outputId": "e2621826-094d-472b-d049-ace4e90dc703"
      },
      "id": "1V9De3Xjsgle",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "36/36 [==============================] - 1s 9ms/step - loss: 2.6787 - accuracy: 0.1603 - val_loss: 2.5820 - val_accuracy: 0.1944\n",
            "Epoch 2/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.6057 - accuracy: 0.1943 - val_loss: 2.5726 - val_accuracy: 0.1944\n",
            "Epoch 3/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.5970 - accuracy: 0.1943 - val_loss: 2.5736 - val_accuracy: 0.1944\n",
            "Epoch 4/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.5772 - accuracy: 0.1943 - val_loss: 2.5457 - val_accuracy: 0.1944\n",
            "Epoch 5/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.5597 - accuracy: 0.1943 - val_loss: 2.5539 - val_accuracy: 0.1944\n",
            "Epoch 6/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.5383 - accuracy: 0.2038 - val_loss: 2.4768 - val_accuracy: 0.1979\n",
            "Epoch 7/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.4941 - accuracy: 0.2239 - val_loss: 2.4483 - val_accuracy: 0.2118\n",
            "Epoch 8/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.4266 - accuracy: 0.2352 - val_loss: 2.3612 - val_accuracy: 0.2361\n",
            "Epoch 9/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.3908 - accuracy: 0.2422 - val_loss: 2.3268 - val_accuracy: 0.2361\n",
            "Epoch 10/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.3789 - accuracy: 0.2317 - val_loss: 2.3884 - val_accuracy: 0.2188\n",
            "Epoch 11/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.3646 - accuracy: 0.2343 - val_loss: 2.3062 - val_accuracy: 0.2465\n",
            "Epoch 12/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 2.3287 - accuracy: 0.2535 - val_loss: 2.3034 - val_accuracy: 0.2396\n",
            "Epoch 13/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 2.3146 - accuracy: 0.2474 - val_loss: 2.2991 - val_accuracy: 0.2569\n",
            "Epoch 14/100\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.3132 - accuracy: 0.2639 - val_loss: 2.2922 - val_accuracy: 0.2639\n",
            "Epoch 15/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2923 - accuracy: 0.2622 - val_loss: 2.2778 - val_accuracy: 0.2569\n",
            "Epoch 16/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2991 - accuracy: 0.2692 - val_loss: 2.2852 - val_accuracy: 0.2604\n",
            "Epoch 17/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.2966 - accuracy: 0.2544 - val_loss: 2.2775 - val_accuracy: 0.2674\n",
            "Epoch 18/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2776 - accuracy: 0.2631 - val_loss: 2.3044 - val_accuracy: 0.2431\n",
            "Epoch 19/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.2645 - accuracy: 0.2857 - val_loss: 2.3540 - val_accuracy: 0.2049\n",
            "Epoch 20/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2781 - accuracy: 0.2631 - val_loss: 2.2688 - val_accuracy: 0.2708\n",
            "Epoch 21/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.2674 - accuracy: 0.2735 - val_loss: 2.3184 - val_accuracy: 0.2431\n",
            "Epoch 22/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.2857 - accuracy: 0.2718 - val_loss: 2.2645 - val_accuracy: 0.2535\n",
            "Epoch 23/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.2511 - accuracy: 0.2805 - val_loss: 2.3132 - val_accuracy: 0.2569\n",
            "Epoch 24/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2740 - accuracy: 0.2787 - val_loss: 2.2803 - val_accuracy: 0.2639\n",
            "Epoch 25/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.2724 - accuracy: 0.2796 - val_loss: 2.2966 - val_accuracy: 0.2500\n",
            "Epoch 26/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2442 - accuracy: 0.2848 - val_loss: 2.2765 - val_accuracy: 0.2674\n",
            "Epoch 27/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2398 - accuracy: 0.2944 - val_loss: 2.2841 - val_accuracy: 0.2569\n",
            "Epoch 28/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.2482 - accuracy: 0.2622 - val_loss: 2.2681 - val_accuracy: 0.2639\n",
            "Epoch 29/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.2374 - accuracy: 0.2970 - val_loss: 2.2571 - val_accuracy: 0.2639\n",
            "Epoch 30/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2195 - accuracy: 0.2936 - val_loss: 2.3729 - val_accuracy: 0.2431\n",
            "Epoch 31/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.2739 - accuracy: 0.2840 - val_loss: 2.2733 - val_accuracy: 0.2465\n",
            "Epoch 32/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.2034 - accuracy: 0.2979 - val_loss: 2.2523 - val_accuracy: 0.2847\n",
            "Epoch 33/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.2213 - accuracy: 0.2866 - val_loss: 2.2632 - val_accuracy: 0.2431\n",
            "Epoch 34/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1890 - accuracy: 0.2901 - val_loss: 2.2276 - val_accuracy: 0.2986\n",
            "Epoch 35/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2096 - accuracy: 0.2970 - val_loss: 2.2146 - val_accuracy: 0.3021\n",
            "Epoch 36/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1905 - accuracy: 0.3023 - val_loss: 2.3484 - val_accuracy: 0.2431\n",
            "Epoch 37/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2207 - accuracy: 0.2796 - val_loss: 2.2296 - val_accuracy: 0.2986\n",
            "Epoch 38/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.2191 - accuracy: 0.2892 - val_loss: 2.2380 - val_accuracy: 0.2604\n",
            "Epoch 39/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1849 - accuracy: 0.2927 - val_loss: 2.2066 - val_accuracy: 0.3090\n",
            "Epoch 40/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1615 - accuracy: 0.3075 - val_loss: 2.2242 - val_accuracy: 0.2986\n",
            "Epoch 41/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1689 - accuracy: 0.3057 - val_loss: 2.2112 - val_accuracy: 0.2986\n",
            "Epoch 42/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1523 - accuracy: 0.3223 - val_loss: 2.2486 - val_accuracy: 0.2708\n",
            "Epoch 43/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1431 - accuracy: 0.3206 - val_loss: 2.2096 - val_accuracy: 0.2951\n",
            "Epoch 44/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1502 - accuracy: 0.3240 - val_loss: 2.3867 - val_accuracy: 0.2569\n",
            "Epoch 45/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.2079 - accuracy: 0.3153 - val_loss: 2.2023 - val_accuracy: 0.3125\n",
            "Epoch 46/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.2151 - accuracy: 0.2909 - val_loss: 2.1901 - val_accuracy: 0.3090\n",
            "Epoch 47/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1534 - accuracy: 0.3118 - val_loss: 2.2078 - val_accuracy: 0.2812\n",
            "Epoch 48/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1495 - accuracy: 0.3258 - val_loss: 2.2737 - val_accuracy: 0.2778\n",
            "Epoch 49/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1578 - accuracy: 0.3040 - val_loss: 2.3084 - val_accuracy: 0.2743\n",
            "Epoch 50/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.1380 - accuracy: 0.3284 - val_loss: 2.2218 - val_accuracy: 0.2917\n",
            "Epoch 51/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1673 - accuracy: 0.3171 - val_loss: 2.1904 - val_accuracy: 0.3160\n",
            "Epoch 52/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1150 - accuracy: 0.3301 - val_loss: 2.1988 - val_accuracy: 0.3125\n",
            "Epoch 53/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1387 - accuracy: 0.3162 - val_loss: 2.1934 - val_accuracy: 0.3229\n",
            "Epoch 54/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1032 - accuracy: 0.3336 - val_loss: 2.2372 - val_accuracy: 0.2708\n",
            "Epoch 55/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1027 - accuracy: 0.3458 - val_loss: 2.1788 - val_accuracy: 0.3264\n",
            "Epoch 56/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0903 - accuracy: 0.3406 - val_loss: 2.1749 - val_accuracy: 0.3333\n",
            "Epoch 57/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0818 - accuracy: 0.3397 - val_loss: 2.2525 - val_accuracy: 0.2708\n",
            "Epoch 58/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1200 - accuracy: 0.3267 - val_loss: 2.2354 - val_accuracy: 0.2986\n",
            "Epoch 59/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1158 - accuracy: 0.3310 - val_loss: 2.2746 - val_accuracy: 0.2500\n",
            "Epoch 60/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1096 - accuracy: 0.3249 - val_loss: 2.2105 - val_accuracy: 0.2986\n",
            "Epoch 61/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1098 - accuracy: 0.3458 - val_loss: 2.2425 - val_accuracy: 0.2986\n",
            "Epoch 62/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1026 - accuracy: 0.3336 - val_loss: 2.1894 - val_accuracy: 0.3160\n",
            "Epoch 63/100\n",
            "36/36 [==============================] - 0s 9ms/step - loss: 2.0907 - accuracy: 0.3484 - val_loss: 2.1902 - val_accuracy: 0.3229\n",
            "Epoch 64/100\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.0771 - accuracy: 0.3476 - val_loss: 2.2091 - val_accuracy: 0.2951\n",
            "Epoch 65/100\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.0936 - accuracy: 0.3354 - val_loss: 2.2068 - val_accuracy: 0.3090\n",
            "Epoch 66/100\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 2.1011 - accuracy: 0.3301 - val_loss: 2.1873 - val_accuracy: 0.3229\n",
            "Epoch 67/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0937 - accuracy: 0.3371 - val_loss: 2.2676 - val_accuracy: 0.2951\n",
            "Epoch 68/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.1068 - accuracy: 0.3476 - val_loss: 2.2137 - val_accuracy: 0.3160\n",
            "Epoch 69/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0763 - accuracy: 0.3571 - val_loss: 2.2309 - val_accuracy: 0.3021\n",
            "Epoch 70/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0921 - accuracy: 0.3380 - val_loss: 2.1817 - val_accuracy: 0.3125\n",
            "Epoch 71/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0889 - accuracy: 0.3371 - val_loss: 2.2071 - val_accuracy: 0.2951\n",
            "Epoch 72/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0775 - accuracy: 0.3484 - val_loss: 2.2042 - val_accuracy: 0.3229\n",
            "Epoch 73/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0541 - accuracy: 0.3624 - val_loss: 2.2488 - val_accuracy: 0.3090\n",
            "Epoch 74/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.1182 - accuracy: 0.3293 - val_loss: 2.2766 - val_accuracy: 0.2639\n",
            "Epoch 75/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0866 - accuracy: 0.3415 - val_loss: 2.2634 - val_accuracy: 0.2917\n",
            "Epoch 76/100\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 2.0618 - accuracy: 0.3458 - val_loss: 2.1822 - val_accuracy: 0.3194\n",
            "Epoch 77/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0526 - accuracy: 0.3493 - val_loss: 2.2731 - val_accuracy: 0.2882\n",
            "Epoch 78/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0617 - accuracy: 0.3502 - val_loss: 2.2040 - val_accuracy: 0.3090\n",
            "Epoch 79/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0470 - accuracy: 0.3571 - val_loss: 2.2498 - val_accuracy: 0.3194\n",
            "Epoch 80/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0482 - accuracy: 0.3589 - val_loss: 2.2387 - val_accuracy: 0.2986\n",
            "Epoch 81/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0601 - accuracy: 0.3571 - val_loss: 2.2614 - val_accuracy: 0.2917\n",
            "Epoch 82/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0366 - accuracy: 0.3789 - val_loss: 2.2134 - val_accuracy: 0.3229\n",
            "Epoch 83/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0675 - accuracy: 0.3423 - val_loss: 2.2167 - val_accuracy: 0.3090\n",
            "Epoch 84/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0680 - accuracy: 0.3345 - val_loss: 2.1850 - val_accuracy: 0.3229\n",
            "Epoch 85/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0698 - accuracy: 0.3545 - val_loss: 2.2260 - val_accuracy: 0.3056\n",
            "Epoch 86/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0508 - accuracy: 0.3606 - val_loss: 2.2439 - val_accuracy: 0.3090\n",
            "Epoch 87/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0533 - accuracy: 0.3554 - val_loss: 2.1891 - val_accuracy: 0.3160\n",
            "Epoch 88/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0370 - accuracy: 0.3606 - val_loss: 2.2063 - val_accuracy: 0.3160\n",
            "Epoch 89/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.0443 - accuracy: 0.3632 - val_loss: 2.2283 - val_accuracy: 0.3194\n",
            "Epoch 90/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0364 - accuracy: 0.3493 - val_loss: 2.2323 - val_accuracy: 0.3229\n",
            "Epoch 91/100\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 2.0369 - accuracy: 0.3554 - val_loss: 2.2208 - val_accuracy: 0.3090\n",
            "Epoch 92/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0386 - accuracy: 0.3563 - val_loss: 2.2010 - val_accuracy: 0.3056\n",
            "Epoch 93/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0104 - accuracy: 0.3650 - val_loss: 2.2149 - val_accuracy: 0.3194\n",
            "Epoch 94/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0143 - accuracy: 0.3624 - val_loss: 2.2044 - val_accuracy: 0.3194\n",
            "Epoch 95/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0230 - accuracy: 0.3519 - val_loss: 2.2126 - val_accuracy: 0.3299\n",
            "Epoch 96/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0056 - accuracy: 0.3754 - val_loss: 2.2371 - val_accuracy: 0.3125\n",
            "Epoch 97/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0292 - accuracy: 0.3502 - val_loss: 2.2637 - val_accuracy: 0.3056\n",
            "Epoch 98/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0446 - accuracy: 0.3502 - val_loss: 2.2049 - val_accuracy: 0.3056\n",
            "Epoch 99/100\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 2.0173 - accuracy: 0.3528 - val_loss: 2.2146 - val_accuracy: 0.3160\n",
            "Epoch 100/100\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 2.0728 - accuracy: 0.3423 - val_loss: 2.3108 - val_accuracy: 0.2882\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f29a1dfc910>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "neural net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4677b729c6ab4237ab4345d8d3c9ada7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a139dc14b3445ebabc6d9a9f1daf720",
              "IPY_MODEL_e2b6911299d949f38891c4b7afdad721",
              "IPY_MODEL_f826ad9260534c0293145487b1c69d1e"
            ],
            "layout": "IPY_MODEL_71cd52facb504d3db4909c36390e802a"
          }
        },
        "6a139dc14b3445ebabc6d9a9f1daf720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f1fa18498e8435c9ddae3a2ad2b15f1",
            "placeholder": "​",
            "style": "IPY_MODEL_eeb83734567740daa46a3e763c2b6696",
            "value": "100%"
          }
        },
        "e2b6911299d949f38891c4b7afdad721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27928ed925164dea80c525ae802ee491",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97f4a0a2a0514caca90387c176b074a8",
            "value": 80
          }
        },
        "f826ad9260534c0293145487b1c69d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1507cfae10274087a967724271e312eb",
            "placeholder": "​",
            "style": "IPY_MODEL_f2e6b37f070f4b4dbf5569d8e047924e",
            "value": " 80/80 [17:08&lt;00:00, 13.73s/it]"
          }
        },
        "71cd52facb504d3db4909c36390e802a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f1fa18498e8435c9ddae3a2ad2b15f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb83734567740daa46a3e763c2b6696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27928ed925164dea80c525ae802ee491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f4a0a2a0514caca90387c176b074a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1507cfae10274087a967724271e312eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2e6b37f070f4b4dbf5569d8e047924e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}