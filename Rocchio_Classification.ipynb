{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6E0Xl4n36O2"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wDYBLciT4BbR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import random\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IJYcAUNJ4H-z"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "8V3_JFD74GCN"
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Kk7RA4Ja4ZLD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Stop Words- 326\n"
     ]
    }
   ],
   "source": [
    "nlp_spacy = spacy.load('en_core_web_sm')\n",
    "\n",
    "#Storing English Stop Words in a List\n",
    "english_stop_words = nlp_spacy.Defaults.stop_words\n",
    "print(\"English Stop Words-\",len(english_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msWyw3745UZV"
   },
   "source": [
    "# Reading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8cKL7oBM6W3H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of training comments = 1436\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"Train.csv\")\n",
    "print(\"No of training comments =\",train_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EUt04Djf6W96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of Labels in Training Dataset\n",
      "\n",
      "POLITICS                279\n",
      "SOCIAL                  152\n",
      "RELIGION                147\n",
      "LAW/ORDER               136\n",
      "SOCIAL ISSUES           134\n",
      "HEALTH                  127\n",
      "ECONOMY                  86\n",
      "FARMING                  78\n",
      "SPORTS                   49\n",
      "EDUCATION                43\n",
      "RELATIONSHIPS            39\n",
      "WILDLIFE/ENVIRONMENT     36\n",
      "OPINION/ESSAY            26\n",
      "LOCALCHIEFS              25\n",
      "CULTURE                  23\n",
      "WITCHCRAFT               16\n",
      "MUSIC                    15\n",
      "TRANSPORT                11\n",
      "ARTS AND CRAFTS           7\n",
      "FLOODING                  7\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribution of Labels in Training Dataset\\n\")\n",
    "print(train_df.Label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of test comments = 620\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"Test.csv\")\n",
    "print(\"No of test comments =\",test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading 1000 common Chichewa words\n",
    "\n",
    "stop_df = pd.read_csv(\"stopwords.csv\")\n",
    "chichewa_1000_words = dict(zip(stop_df[\"Chichewa\"], stop_df[\"in English\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some examples of chichewa words and their english meanings\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kukambirana', 'discuss'),\n",
       " ('poyambira', 'chord'),\n",
       " ('nyengo', 'season'),\n",
       " ('kufulumira', 'hurry'),\n",
       " ('kum’mawa', 'east')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Some examples of chichewa words and their english meanings\")\n",
    "random.sample(list(chichewa_1000_words.items()),5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower Cased, keep only ASCII characters, tokenized, remove punctuation, remove stop words (flag used), removed digits\n",
    "\n",
    "def preprocess(text, remove_stop=False):\n",
    "    \n",
    "    #Convert to lower case\n",
    "    text_2 = text.lower()\n",
    "\n",
    "    # keep only ascii characters\n",
    "    text_3 = re.sub(r\"[^a-zA-ZÀ-ÿ]\", \" \", text_2)\n",
    "\n",
    "    spacy_object = nlp_spacy(text_3)\n",
    "    sentences = list(spacy_object.sents) \n",
    "    tokens = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        for token in sentence:\n",
    "            if not(token.is_punct):  #Remove Punctuations\n",
    "                if remove_stop and token.text in chichewa_1000_words.keys(): #Check if word is in the list of 1000 common Chichewa words \n",
    "                    if not (chichewa_1000_words[token.text] in english_stop_words): #If word is a stop word, remove it.\n",
    "                        tokens.append(token.text)  \n",
    "                else:\n",
    "                    tokens.append(token.text)\n",
    "\n",
    "    tokenized = \" \".join(tokens) #Join all tokens as a string.\n",
    "    \n",
    "    result = ''.join([i for i in tokenized if not i.isdigit()]) #Remove all digits\n",
    "  \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_clean = train_df.copy()\n",
    "for i in train_df_clean.index:\n",
    "    train_df_clean.loc[i,\"Text\"] = preprocess(train_df_clean.loc[i,\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_clean = test_df.copy()\n",
    "for i in test_df_clean.index:\n",
    "    test_df_clean.loc[i,\"Text\"] = preprocess(test_df_clean.loc[i,\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_no_stop = train_df.copy()\n",
    "for i in train_df_no_stop.index:\n",
    "    train_df_no_stop.loc[i,\"Text\"] = preprocess(train_df_no_stop.loc[i,\"Text\"], remove_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_no_stop = test_df.copy()\n",
    "for i in test_df_no_stop.index:\n",
    "    test_df_no_stop.loc[i,\"Text\"] = preprocess(test_df_no_stop.loc[i,\"Text\"], remove_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Raw Data-\n",
      "\n",
      " Mwangonde: Khansala wachinyamata Akamati achinyamata ndi atsogoleri a mawa, ambiri amaganiza kuti izi ndi nkhambakamwa chabe. Koma achinyamata ena, monga Lusubilo Mwangonde, akukwaniritsa akupherezet\n",
      "\n",
      "Example Processed Data-\n",
      "\n",
      "  mwangonde   khansala wachinyamata akamati achinyamata ndi atsogoleri a mawa   ambiri amaganiza kuti izi ndi nkhambakamwa chabe   koma achinyamata ena   monga lusubilo mwangonde   akukwaniritsa akuph\n",
      "\n",
      "Example Processed Data without stop words-\n",
      "\n",
      "  mwangonde   khansala wachinyamata akamati achinyamata atsogoleri mawa   ambiri amaganiza nkhambakamwa chabe   achinyamata ena   monga lusubilo mwangonde   akukwaniritsa akupherezetsa mawuwa osati po\n"
     ]
    }
   ],
   "source": [
    "print(\"Example Raw Data-\\n\")\n",
    "print(train_df.loc[0,\"Text\"][0:200])\n",
    "print(\"\\nExample Processed Data-\\n\")\n",
    "print(train_df_clean.loc[0,\"Text\"][0:200])\n",
    "print(\"\\nExample Processed Data without stop words-\\n\")\n",
    "print(train_df_no_stop.loc[0,\"Text\"][0:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rocchio Model (Score on website - 0.6419354838709678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_clean.Text\n",
    "y_train = train_df_clean.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = imblearn.pipeline.Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', NearestCentroid()),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation accuracy = 0.6232868757259\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model_1, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"5-fold cross validation accuracy = {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', NearestCentroid())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = {\"ID\":[],\"Label\":[]}\n",
    "for i in sample_df.ID:\n",
    "\n",
    "    submission_dict[\"ID\"].append(i)\n",
    "    \n",
    "    text = test_df_clean.loc[test_df_clean['ID'] == i,\"Text\"].values[0]\n",
    "    text_input = [text]\n",
    "    pred = model_1.predict(text_input)\n",
    "    \n",
    "    submission_dict[\"Label\"].append(pred.item())\n",
    "\n",
    "submission_df_1 = pd.DataFrame(submission_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_sQaPRMWO</td>\n",
       "      <td>LAW/ORDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_TanclvfR</td>\n",
       "      <td>SOCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_CNbveyvk</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_MclKMhyP</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_rNrmXOGD</td>\n",
       "      <td>ECONOMY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID          Label\n",
       "0  ID_sQaPRMWO      LAW/ORDER\n",
       "1  ID_TanclvfR         SOCIAL\n",
       "2  ID_CNbveyvk  SOCIAL ISSUES\n",
       "3  ID_MclKMhyP  SOCIAL ISSUES\n",
       "4  ID_rNrmXOGD        ECONOMY"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df_1.to_csv('Rocchio_Predicted_Submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rocchio Model (with Oversampling) (Score on website - 0.632258064516129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_clean.Text\n",
    "y_train = train_df_clean.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = imblearn.pipeline.Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('ros', RandomOverSampler()),\n",
    "                    ('oversampler', SMOTE()),\n",
    "                    ('clf', NearestCentroid()),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation accuracy = 0.6246806039488966\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model_2, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"5-fold cross validation accuracy = {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('ros', RandomOverSampler()), ('oversampler', SMOTE()),\n",
       "                ('clf', NearestCentroid())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = {\"ID\":[],\"Label\":[]}\n",
    "for i in sample_df.ID:\n",
    "\n",
    "    submission_dict[\"ID\"].append(i)\n",
    "    \n",
    "    text = test_df_clean.loc[test_df_clean['ID'] == i,\"Text\"].values[0]\n",
    "    text_input = [text]\n",
    "    pred = model_2.predict(text_input)\n",
    "    \n",
    "    submission_dict[\"Label\"].append(pred.item())\n",
    "\n",
    "submission_df_2 = pd.DataFrame(submission_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_sQaPRMWO</td>\n",
       "      <td>LAW/ORDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_TanclvfR</td>\n",
       "      <td>SOCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_CNbveyvk</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_MclKMhyP</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_rNrmXOGD</td>\n",
       "      <td>ECONOMY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID          Label\n",
       "0  ID_sQaPRMWO      LAW/ORDER\n",
       "1  ID_TanclvfR         SOCIAL\n",
       "2  ID_CNbveyvk  SOCIAL ISSUES\n",
       "3  ID_MclKMhyP  SOCIAL ISSUES\n",
       "4  ID_rNrmXOGD        ECONOMY"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df_2.to_csv('Rocchio_Predicted_Submission_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rocchio Model (without Stop Words) (Score on website - 0.6387096774193548)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_no_stop.Text\n",
    "y_train = train_df_no_stop.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = imblearn.pipeline.Pipeline([('vect', CountVectorizer()),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', NearestCentroid()),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold cross validation accuracy = 0.6225924312814557\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(model_3, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"5-fold cross validation accuracy = {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', NearestCentroid())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_dict = {\"ID\":[],\"Label\":[]}\n",
    "for i in sample_df.ID:\n",
    "\n",
    "    submission_dict[\"ID\"].append(i)\n",
    "    \n",
    "    text = test_df_no_stop.loc[test_df_no_stop['ID'] == i,\"Text\"].values[0]\n",
    "    text_input = [text]\n",
    "    pred = model_3.predict(text_input)\n",
    "    \n",
    "    submission_dict[\"Label\"].append(pred.item())\n",
    "\n",
    "submission_df_3 = pd.DataFrame(submission_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_sQaPRMWO</td>\n",
       "      <td>LAW/ORDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_TanclvfR</td>\n",
       "      <td>SOCIAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_CNbveyvk</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_MclKMhyP</td>\n",
       "      <td>SOCIAL ISSUES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_rNrmXOGD</td>\n",
       "      <td>ECONOMY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID          Label\n",
       "0  ID_sQaPRMWO      LAW/ORDER\n",
       "1  ID_TanclvfR         SOCIAL\n",
       "2  ID_CNbveyvk  SOCIAL ISSUES\n",
       "3  ID_MclKMhyP  SOCIAL ISSUES\n",
       "4  ID_rNrmXOGD        ECONOMY"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission_df_3.to_csv('Rocchio_Predicted_Submission_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "combiner = pd.read_csv(\"combiner.csv\")\n",
    "combiner['Rocchio'] = submission_df_1['Label']\n",
    "combiner.to_csv('combiner.csv', index = False)\n",
    "combiner.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Rocchio_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
